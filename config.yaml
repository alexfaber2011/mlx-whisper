# MLX Whisper Wyoming Protocol Server Configuration

server:
  host: "0.0.0.0"  # Listen on all interfaces
  port: 10300      # Wyoming protocol port (default 10300)
  preload_model: true  # Load model at startup for faster first transcription

model:
  name: "mlx-community/whisper-large-v3-turbo"  # Whisper model to use
  # Alternative models:
  # - mlx-community/whisper-large-v3
  # - mlx-community/whisper-medium
  # - mlx-community/whisper-small
  # - mlx-community/whisper-base
  # - mlx-community/whisper-tiny
  language: null  # Default language code (null = auto-detect)
  load_retry_count: 3  # Number of retries for model loading
  load_retry_delay: 5  # Delay between retries (seconds)

audio:
  max_buffer_size_mb: 100  # Maximum audio buffer size in MB
  sample_rate: 16000  # Target sample rate
  channels: 1  # Target channels (mono)
  width: 2  # Sample width in bytes

logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "json"  # json or text
  include_request_ids: true  # Add unique request IDs to logs

metrics:
  enabled: true  # Enable performance metrics collection
  track_inference_time: true
  track_audio_duration: true

health_check:
  enabled: true  # Enable health check endpoint
  include_model_status: true  # Include model load status in health check